{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from numba import cuda, njit, int32\n",
    "\n",
    "@cuda.jit\n",
    "def counting_sort_parallel(arr, exp, output, count):\n",
    "    tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    if tid < arr.size:\n",
    "        # Contar a ocorrência de cada dígito\n",
    "        index = (arr[tid] // exp) % 10\n",
    "        cuda.atomic.add(count, index, 1)\n",
    "        \n",
    "    # Sincronização das threads\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Cálculo da posição real dos elementos\n",
    "    if tid == 0:\n",
    "        for i in range(1, 10):\n",
    "            count[i] += count[i - 1]\n",
    "\n",
    "    # Sincronização das threads\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Montar o array de saída baseado na contagem\n",
    "    if tid < arr.size:\n",
    "        index = (arr[tid] // exp) % 10\n",
    "        position = count[index] - 1\n",
    "        output[position] = arr[tid]\n",
    "        cuda.atomic.sub(count, index, 1)\n",
    "\n",
    "def radix_sort_cuda(arr):\n",
    "    max_val = np.max(arr)\n",
    "    exp = 1\n",
    "    while max_val // exp > 0:\n",
    "        count = cuda.to_device(np.zeros(10, dtype=int32))\n",
    "        output = cuda.to_device(np.zeros(arr.size, dtype=int32))\n",
    "        \n",
    "        # Configurar threads e blocos para o tamanho do array\n",
    "        threads_per_block = 256\n",
    "        blocks_per_grid = (arr.size + threads_per_block - 1) // threads_per_block\n",
    "        \n",
    "        # Chamamos o counting sort paralelizado em CUDA\n",
    "        counting_sort_parallel[blocks_per_grid, threads_per_block](arr, exp, output, count)\n",
    "        \n",
    "        # Copiar o resultado de volta ao array original\n",
    "        arr = output.copy_to_host()\n",
    "        exp *= 10\n",
    "        \n",
    "    return arr\n",
    "\n",
    "# Função para testar o Radix Sort paralelo\n",
    "def test_radix_sort_parallel():\n",
    "    sizes = [100, 1000, 10000, 100000, 1000000, 10000000]\n",
    "    results = []\n",
    "\n",
    "    for size in sizes:\n",
    "        arr = np.random.randint(0, size, size).astype(np.int32)\n",
    "        arr_device = cuda.to_device(arr)\n",
    "\n",
    "        start_time = time.time()\n",
    "        sorted_arr = radix_sort_cuda(arr_device)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        results.append((size, end_time - start_time))\n",
    "\n",
    "    print(\"Tamanho do Array | Tempo de Execução (s)\")\n",
    "    for size, duration in results:\n",
    "        print(f\"{size:<15} | {duration:.6f}\")\n",
    "\n",
    "test_radix_sort_parallel()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
